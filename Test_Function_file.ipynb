{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from geopy import distance\n",
    "import geopandas\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import tensorflow as tf\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to test new data for Fraud classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "def predict_fraud(test_file_path, model_file_path):\n",
    "    \n",
    "    def calc_distance(lat1, lon1, lat2, lon2):\n",
    "        R = 6373.0\n",
    "\n",
    "        lat1 = radians(lat1)\n",
    "        lon1 = radians(lon1)\n",
    "        lat2 = radians(lat2)\n",
    "        lon2 = radians(lon2)\n",
    "\n",
    "        dlon = lon2 - lon1\n",
    "        dlat = lat2 - lat1\n",
    "\n",
    "        a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "        c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "        distance = R * c\n",
    "\n",
    "        return distance\n",
    "\n",
    "    # Load test data from file\n",
    "    test_data = pd.read_csv(test_file_path)\n",
    "\n",
    "    # Load model from file\n",
    "    model = Sequential()\n",
    "    model.load_weights(model_file_path)\n",
    "\n",
    "    # Perform data preprocessing on test data\n",
    "    test_data['trans_date_trans_time'] = pd.to_datetime(test_data['trans_date_trans_time'])\n",
    "    test_data['hour_of_day'] = test_data['trans_date_trans_time'].dt.hour\n",
    "    test_data['day_of_week'] = test_data['trans_date_trans_time'].dt.dayofweek\n",
    "    test_data['dob'] = pd.to_datetime(test_data['dob'])\n",
    "    test_data['age'] = (test_data['trans_date_trans_time'] - test_data['dob']).dt.days // 365\n",
    "    test_data['distance'] = np.vectorize(calc_distance)(test_data['lat'], test_data['long'], test_data['merch_lat'], test_data['merch_long'])\n",
    "    test_data.drop(columns=['trans_date_trans_time', 'cc_num', 'merchant', 'first', 'last', 'street', 'city', 'state', 'zip',\n",
    "                     'lat', 'long', 'merch_lat', 'merch_long', 'job', 'dob', 'trans_num', 'unix_time'], inplace=True)\n",
    "    test_data = pd.get_dummies(test_data, columns=['category', 'gender'])\n",
    "    scaler = StandardScaler()\n",
    "    test_data_scaled = scaler.fit_transform(test_data)\n",
    "\n",
    "    # Make predictions on test data\n",
    "    y_pred = model.predict(test_data_scaled)\n",
    "    y_pred_binary = np.round(y_pred).flatten()\n",
    "\n",
    "    # Get classification matrix\n",
    "    cm = confusion_matrix(test_data['is_fraud'], y_pred_binary)\n",
    "    accuracy = accuracy_score(test_data['is_fraud'], y_pred_binary)\n",
    "\n",
    "    # Print classification matrix and accuracy\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    # Return classification matrix and accuracy\n",
    "    return cm, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute function on new data\n",
    "# cm, accuracy = predict_fraud('test_data.csv', 'model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
